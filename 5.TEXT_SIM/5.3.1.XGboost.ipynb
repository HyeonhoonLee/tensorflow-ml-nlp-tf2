{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "5.3.1.XGboost.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5FI5uOkZgpB",
        "outputId": "a62f0bf9-40b1-4ab1-b977-122e07a45100"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiAKIXf2Zc8e"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/DataCollection/tensorflow-ml-nlp-tf2/5.TEXT_SIM')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q1Rule1aZfU0",
        "outputId": "e08bc32e-fd44-42c7-deeb-dc88320c7cca"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/DataCollection/tensorflow-ml-nlp-tf2/5.TEXT_SIM'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULt8q831XtKa"
      },
      "source": [
        "# XGboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbTxJCmkXtKg"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import json\n",
        "\n",
        "from sklearn.model_selection  import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgD7x-N_XtKg"
      },
      "source": [
        "### 설정된 값들"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-YeEOjGXtKh"
      },
      "source": [
        "DATA_IN_PATH = './data_in/'\n",
        "DATA_OUT_PATH = './data_out/'\n",
        "\n",
        "TRAIN_Q1_DATA_FILE = 'train_q1.npy'\n",
        "TRAIN_Q2_DATA_FILE = 'train_q2.npy'\n",
        "TRAIN_LABEL_DATA_FILE = 'train_label.npy'\n",
        "\n",
        "\n",
        "# 훈련 데이터 가져오는 부분이다.\n",
        "train_q1_data = np.load(open(DATA_IN_PATH + TRAIN_Q1_DATA_FILE, 'rb'))\n",
        "train_q2_data = np.load(open(DATA_IN_PATH + TRAIN_Q2_DATA_FILE, 'rb'))\n",
        "train_labels = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA_FILE, 'rb'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BNWlaGoXtKh"
      },
      "source": [
        "train_input = np.stack((train_q1_data, train_q2_data), axis=1) \n",
        "# np.stack은 두 질문을 하나의 쌍으로 만든다.\n",
        "# 예를 들어 질문 [A]와 질문 [B]가 있을 때, 이 질문을 하나로 묶어 [[A],[B]] 형태로 만든다."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBm1gcBIXtKi",
        "outputId": "3bf7f0e0-2e92-4dbb-8bd4-c49833d35372"
      },
      "source": [
        "print(train_input.shape)  # (전체 데이터 갯수, 1쌍, 질문 길이)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(298526, 2, 31)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_7JUbDAXtKi"
      },
      "source": [
        "### 훈련 셋과 평가 셋 나누기¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBaNUMFtXtKi"
      },
      "source": [
        "train_input, eval_input, train_label, eval_label = train_test_split(train_input, train_labels, test_size=0.2, random_state=4242)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv-SMWi9XtKi"
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAM8eFANXtKj"
      },
      "source": [
        "### 모델 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhIitt96XtKj"
      },
      "source": [
        "train_data = xgb.DMatrix(train_input.sum(axis=1), label=train_label) # 학습 데이터 읽어 오기\n",
        "eval_data = xgb.DMatrix(eval_input.sum(axis=1), label=eval_label) # 평가 데이터 읽어 오기\n",
        "\n",
        "data_list = [(train_data, 'train'), (eval_data, 'valid')]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ze--NPza733",
        "outputId": "9139025c-64f6-4cb7-8032-b640ed271941"
      },
      "source": [
        "train_input[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    9,   348,    37, 23601,   316,   348, 15392,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0],\n",
              "       [    9,    37,   293,   348,  6482,     8,  3312,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qtf4lp3a-mK",
        "outputId": "fa2c35fb-ad8c-4296-b05a-adcc7a7423fc"
      },
      "source": [
        "train_input[0].sum(axis=1)  ##어떻게 sum이되는지 print 해보았다."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([40051, 10489])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6pdj0eoXtKk"
      },
      "source": [
        "params = {} # 인자를 통해 XGB모델에 넣어 주자 \n",
        "params['objective'] = 'binary:logistic' # 목적함수인 경우 이진 로지스틱을 사용.\n",
        "params['eval_metric'] = 'rmse' # root mean square error를 사용  \n",
        "\n",
        "bst = xgb.train(params, train_data, num_boost_round = 1000, evals = data_list, early_stopping_rounds=10)\n",
        "#evals : 모델 검증 시 사용할 전체 데이터 쌍"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5N7J58pXtKk"
      },
      "source": [
        "### 테스트 데이터 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTsJLRvBXtKk"
      },
      "source": [
        "TEST_Q1_DATA_FILE = 'test_q1.npy'\n",
        "TEST_Q2_DATA_FILE = 'test_q2.npy'\n",
        "TEST_ID_DATA_FILE = 'test_id.npy'\n",
        "\n",
        "test_q1_data = np.load(open(DATA_IN_PATH + TEST_Q1_DATA_FILE, 'rb'))\n",
        "test_q2_data = np.load(open(DATA_IN_PATH + TEST_Q2_DATA_FILE, 'rb'))\n",
        "# test_id_data = np.load(open(DATA_IN_PATH + TEST_ID_DATA_FILE, 'rb'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JKTU_HSXtKk"
      },
      "source": [
        "### 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXqDXyHVXtKl"
      },
      "source": [
        "test_input = np.stack((test_q1_data, test_q2_data), axis=1) \n",
        "test_data = xgb.DMatrix(test_input.sum(axis=1))\n",
        "test_predict = bst.predict(test_data)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb_remK7eUgR"
      },
      "source": [
        "## test_id_data가 안 불러져서, 그냥 test_predict로만 dataframe을 만들어본다.\n",
        "output_sample = pd.DataFrame({'is_duplicate': test_predict})"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "kMEfuU4OegK-",
        "outputId": "a35c2777-9f57-4470-e4fe-1d32fbfa4354"
      },
      "source": [
        "output_sample.head(10)  ## 이 값이 곧 유사도(확률)인듯.(1이 duplicate로 supervised learning 했으니까)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.384445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.572531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.797910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.039513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.638644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.069173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.874005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.346784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.804683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.453130</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_duplicate\n",
              "0      0.384445\n",
              "1      0.572531\n",
              "2      0.797910\n",
              "3      0.039513\n",
              "4      0.638644\n",
              "5      0.069173\n",
              "6      0.874005\n",
              "7      0.346784\n",
              "8      0.804683\n",
              "9      0.453130"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTJR1k1bXtKl"
      },
      "source": [
        "if not os.path.exists(DATA_OUT_PATH):\n",
        "    os.makedirs(DATA_OUT_PATH)\n",
        "    \n",
        "output = pd.DataFrame({'test_id': test_id_data, 'is_duplicate': test_predict})\n",
        "output.to_csv(DATA_OUT_PATH + 'simple_xgb.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIGn2KDyXtKl"
      },
      "source": [
        " # TF-IDF나 word2vec으로 데이터의 입력값의 형태를 바꾼 후 모델을 적용하면 성능이 더 좋아질듯.\n",
        " ## 현재는 그냥 vocab index에 sum 한 값을 넣어줘서 성능이 안 좋은듯."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}