{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day4_2_Ma_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZUMwiPv0M5v",
        "outputId": "6a1a7cb0-c294-4824-91ee-ba74acbf506e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMd15dsV0JIp",
        "outputId": "19687e55-a9d7-43c3-fc9b-7d2ddea65bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/DataCollection/tensorflow-ml-nlp-tf2/5.TEXT_SIM')\n",
        "os.getcwd()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/DataCollection/tensorflow-ml-nlp-tf2/5.TEXT_SIM'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG4_-K7Z6aub"
      },
      "source": [
        "# 모듈 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixJi5iWk6VzH"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adDvEqAvy9dj"
      },
      "source": [
        "# 시각화 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWgWnGb6y9dj"
      },
      "source": [
        "def plot_graphs(history, string):\n",
        "    plt.plot(history.history[string])\n",
        "    plt.plot(history.history['val_'+string], '')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([string, 'val_'+string])\n",
        "    plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psZxI83hy9dk"
      },
      "source": [
        "# 학습 데이터 파일 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GFKv68my9dk"
      },
      "source": [
        "DATA_IN_PATH = './data_in/'\n",
        "DATA_OUT_PATH = './data_out/'\n",
        "TRAIN_Q1_DATA_FILE = 'train_q1.npy'\n",
        "TRAIN_Q2_DATA_FILE = 'train_q2.npy'\n",
        "TRAIN_LABEL_DATA_FILE = 'train_label.npy'\n",
        "DATA_CONFIGS = 'data_configs.json'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXtgmFAYy9dk"
      },
      "source": [
        "# 랜덤 시드 고정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClahCsU4y9dk"
      },
      "source": [
        "SEED_NUM = 1234\n",
        "tf.random.set_seed(SEED_NUM)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGM3FRiSy9dl"
      },
      "source": [
        "# 파일 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLYKvtMFy9dl"
      },
      "source": [
        "q1_data = np.load(open(DATA_IN_PATH + TRAIN_Q1_DATA_FILE, 'rb'))\n",
        "q2_data = np.load(open(DATA_IN_PATH + TRAIN_Q2_DATA_FILE, 'rb'))\n",
        "labels = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA_FILE, 'rb'))\n",
        "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwJwmbN7y9dl"
      },
      "source": [
        "# 모델 하이퍼파라메터 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHiU2qCCy9dl"
      },
      "source": [
        "model_name = 'malstm_similarity'\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 5\n",
        "VALID_SPLIT = 0.1\n",
        "\n",
        "kargs = {\n",
        "    'vocab_size': prepro_configs['vocab_size'],\n",
        "    'embedding_dimension': 100,\n",
        "    'lstm_dimension': 150,\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvXOXlSywPR2"
      },
      "source": [
        "# 모델 선언 및 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjXY8EwCy9dl"
      },
      "source": [
        "class MaLSTM(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, **kargs):\n",
        "        super(MaLSTM, self).__init__(name=model_name)\n",
        "        self.embedding = layers.Embedding(input_dim=kargs['vocab_size'],\n",
        "                                     output_dim=kargs['embedding_dimension'])\n",
        "        self.lstm = layers.LSTM(units=kargs['lstm_dimension'])\n",
        "        \n",
        "    def call(self, x):\n",
        "        x1, x2 = x\n",
        "        x1 = self.embedding(x1)\n",
        "        x2 = self.embedding(x2)\n",
        "        x1 = self.lstm(x1)\n",
        "        x2 = self.lstm(x2)\n",
        "        x = tf.exp(-tf.reduce_sum(tf.abs(x1 - x2), axis=1))\n",
        "        # tf.abs(x1 - x2) => absolute value of distance between two vectors(x1 - x2).\n",
        "        # tf.reduce_sum() => sum of each absoluste value for calculating the manhattan distance.\n",
        "        # tf.exp(-x) => if the distance is far, the value is close to zero. (for providing the similarity (0 ~ 1))\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bxyDy0Zy9dm"
      },
      "source": [
        "model = MaLSTM(**kargs)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szCwxjSvy9dm"
      },
      "source": [
        "# Callback 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtODJTNLy9dm",
        "outputId": "76f54a45-3c76-495d-8571-5c642b151bad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# overfitting을 막기 위한 ealrystop 추가\n",
        "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=1)\n",
        "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
        "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\\\n",
        "\n",
        "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create path if exists\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
        "else:\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
        "    \n",
        "\n",
        "cp_callback = ModelCheckpoint(\n",
        "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./data_out/malstm_similarity -- Folder create complete \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYivfu2Py9dn"
      },
      "source": [
        "# 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGGydOFry9dn"
      },
      "source": [
        "history = model.fit((q1_data, q2_data), labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
        "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttCpWojuy9do"
      },
      "source": [
        "# 결과 플롯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7EqaWEyy9do"
      },
      "source": [
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8BPouahy9do"
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrOvPctZy9do"
      },
      "source": [
        "# 테스트 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLab41oLQSQV"
      },
      "source": [
        "TEST_Q1_DATA_FILE = 'test_q1.npy'\n",
        "TEST_Q2_DATA_FILE = 'test_q2.npy'\n",
        "TEST_ID_DATA_FILE = 'test_id.npy'\n",
        "\n",
        "test_q1_data = np.load(open(DATA_IN_PATH + TEST_Q1_DATA_FILE, 'rb'))\n",
        "test_q2_data = np.load(open(DATA_IN_PATH + TEST_Q2_DATA_FILE, 'rb'))\n",
        "test_id_data = np.load(open(DATA_IN_PATH + TEST_ID_DATA_FILE, 'rb'), allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5OG8_Bpy9do"
      },
      "source": [
        "# 베스트 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbEH2gw_y9dp"
      },
      "source": [
        "SAVE_FILE_NM = 'weights.h5'\n",
        "model.load_weights(os.path.join(DATA_OUT_PATH, model_name, SAVE_FILE_NM))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7flr5nBey9dq"
      },
      "source": [
        "# 베스트 데이터 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwRpQU3py9dq"
      },
      "source": [
        "predictions = model.predict((test_q1_data, test_q2_data), batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0tcgd69Zy9dq"
      },
      "source": [
        "output = pd.DataFrame( data={\"test_id\":test_id_data, \"is_duplicate\": list(predictions)} )\n",
        "output.to_csv(DATA_OUT_PATH+\"rnn_predict.csv\", index=False, quoting=3)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}