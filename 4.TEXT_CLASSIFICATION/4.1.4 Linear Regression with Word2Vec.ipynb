{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "4.1.4 Linear Regression with Word2Vec.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz4TyyC9iatw",
        "outputId": "3d9262d5-f148-4914-c62b-dbcb2499102f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7EfcK8sjA19"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/DataCollection/tensorflow-ml-nlp-tf2/4.TEXT_CLASSIFICATION/')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT-WYdj5jKRf",
        "outputId": "96ba6c6f-6533-4064-e9ec-83b5e893d731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/DataCollection/tensorflow-ml-nlp-tf2/4.TEXT_CLASSIFICATION'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSvZ6vVMf9EZ"
      },
      "source": [
        "## 4.1.3 Linear Regression Example with Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiQlB8F8f9EZ"
      },
      "source": [
        "### Word2Vec Feature Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a4yTBVgf9EZ"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzugrzAJf9Ea"
      },
      "source": [
        "DATA_IN_PATH = './data_in/'\n",
        "DATA_OUT_PATH = './data_out/'\n",
        "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "TEST_SPLIT = 0.2"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZuFWzN9f9Ea"
      },
      "source": [
        "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA) # 전처리된 data를 사용"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRmgYa3skMUs",
        "outputId": "769a3b14-7bc5-43ae-c565-561d524ba739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list(train_data['review'])[:2] ## series data를 바로 list로 바꿀 수 있다."
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stuff going moment mj started listening music watching odd documentary watched wiz watched moonwalker maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent moonwalker part biography part feature film remember going see cinema originally released subtle messages mj feeling towards press also obvious message drugs bad kay visually impressive course michael jackson unless remotely like mj anyway going hate find boring may call mj egotist consenting making movie mj fans would say made fans true really nice actual feature film bit finally starts minutes excluding smooth criminal sequence joe pesci convincing psychopathic powerful drug lord wants mj dead bad beyond mj overheard plans nah joe pesci character ranted wanted people know supplying drugs etc dunno maybe hates mj music lots cool things like mj turning car robot whole speed demon sequence also director must patience saint came filming kiddy bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene bottom line movie people like mj one level another think people stay away try give wholesome message ironically mj bestest buddy movie girl michael jackson truly one talented people ever grace planet guilty well attention gave subject hmmm well know people different behind closed doors know fact either extremely nice stupid guy one sickest liars hope latter',\n",
              " 'classic war worlds timothy hines entertaining film obviously goes great effort lengths faithfully recreate h g wells classic book mr hines succeeds watched film appreciated fact standard predictable hollywood fare comes every year e g spielberg version tom cruise slightest resemblance book obviously everyone looks different things movie envision amateur critics look criticize everything others rate movie important bases like entertained people never agree critics enjoyed effort mr hines put faithful h g wells classic novel found entertaining made easy overlook critics perceive shortcomings']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zijb0FvNf9Ea"
      },
      "source": [
        "reviews = list(train_data['review'])\n",
        "sentiments = list(train_data['sentiment'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQOlvkqEkwr5",
        "outputId": "02d0446f-29fd-4a9e-f2f2-51f5bf2d3a8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "reviews[0].split()[:3]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stuff', 'going', 'moment']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gq6PMa7f9Ea"
      },
      "source": [
        "sentences = []\n",
        "for review in reviews:\n",
        "    sentences.append(review.split())\n",
        "    ## split 함수안에 아무것도 안적혀있으면 띄어쓰기 기준으로 split.. 따라서 split() == split(' ')\n",
        "    ## word2vec을 사용하기 위해서 각 단어로 구분된 리스트로 바꾼다."
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zWOQgHVlVIS",
        "outputId": "578112bc-5c68-4d89-e11c-1684dc1706f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sentences[0][:3]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stuff', 'going', 'moment']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LRJcovim9H7"
      },
      "source": [
        "num_features = 300   # num. of embedding dimensions.\n",
        "min_word_count = 40  # 모델에 의미 있는 단어를 가지고 학습하기 위해 40 미만의 빈도 수의 단어들은 학습 x\n",
        "num_workers = 4      # CPU 쿼드코어를 이용 (사용 프로세스의 갯수)\n",
        "context = 10         # window size. 앞뒤로 10개를 보겠다는 의미\n",
        "downsampling = 1e-3  # 빠른 학습을 위해 정답 단어 라벨에 대한 다운샘플링 비율을 지정. 보통 0.001을 사용\n",
        "##(추가 의견: downsampling 수치가 뭔지에 대해서 약간 찾아봤는데, 전체 단어의 0.001을 어떤 단어가 넘는 순간, \n",
        "##빈번하게 등장한다고 판단하고 이 단어에 대해 다운샘플링을 진행하는 것으로 보임)\n",
        "##출처: https://dalpo0814.tistory.com/13 [deeep]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvogkB-1f9Ea"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
        "   level=logging.INFO)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwf_vsQxf9Ea"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
        "           size=num_features, min_count = min_word_count, \\\n",
        "            window = context, sample = downsampling)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOPnojVYtwcs",
        "outputId": "34cfe668-bcbb-41cc-dfc5-004835e52b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 모델 저장하기\n",
        "model_name = \"300features_40minwords_10context\"\n",
        "model.save(model_name)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 12:26:44,432 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
            "2020-12-06 12:26:44,434 : INFO : not storing attribute vectors_norm\n",
            "2020-12-06 12:26:44,435 : INFO : not storing attribute cum_table\n",
            "2020-12-06 12:26:44,733 : INFO : saved 300features_40minwords_10context\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7IomCu3f9Ea"
      },
      "source": [
        "def get_features(words, model, num_features):  ## 일반적인 look up table을 만드는 것과 동일하다.\n",
        "    feature_vector = np.zeros((num_features),dtype=np.float32) # 하나의 벡터를 만드는 과정에서 속도를 빠르게 하기 위해 np.zeros를 미리 만듦!\n",
        "\n",
        "    num_words = 0\n",
        "    index2word_set = set(model.wv.index2word)  # 단어 vocab\n",
        "\n",
        "    for w in words:\n",
        "        if w in index2word_set:\n",
        "            num_words += 1\n",
        "            feature_vector = np.add(feature_vector, model[w])\n",
        "\n",
        "    feature_vector = np.divide(feature_vector, num_words)\n",
        "    return feature_vector\n",
        "    ## 여기까지하면 리뷰 한 줄에 대한 vectorized representation 만들어진다."
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XJ730koLhnN",
        "outputId": "92c8f8b7-b0e9-4331-87f6-5d0abe515003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "feature_vector = np.zeros((num_features),dtype=np.float32)\n",
        "feature_vector.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2v--y3bHA3d",
        "outputId": "8e94a3a9-0903-4b55-83dc-1e08eb31f43c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model['stuff'].shape  ### model[w]는 각 단어의 vector라는 것을 알기 위해 해봄."
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGG9j-1nf9Ea"
      },
      "source": [
        "def get_dataset(reviews, model, num_features):\n",
        "    dataset = list()\n",
        "\n",
        "    for s in reviews:\n",
        "        dataset.append(get_features(s, model, num_features))\n",
        "\n",
        "    reviewFeatureVecs = np.stack(dataset)\n",
        "    \n",
        "    return reviewFeatureVecs"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYt0iyDDf9Ea",
        "outputId": "7e69b80f-4066-4a6a-e233-9f9ef3f7230a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data_vecs = get_dataset(sentences, model, num_features)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYODJsECNc2y"
      },
      "source": [
        "이하로는 이전 4.1.3(4)의 tf-idf와 동일하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPhPSh5Vf9Ea"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "X = test_data_vecs\n",
        "y = np.array(sentiments)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oCbFfq4f9Ea",
        "outputId": "6dd4d18d-6bca-4a35-dd92-dccb696e9125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lgs = LogisticRegression(class_weight='balanced')\n",
        "lgs.fit(X_train, y_train)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWeFBx3ff9Ea",
        "outputId": "39d2faf5-d176-414d-8d5f-5b72a1028251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predicted = lgs.predict(X_test)\n",
        "from sklearn import metrics\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test, (lgs.predict_proba(X_test)[:, 1]))\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "print(\"------------\")\n",
        "print(\"Accuracy: %f\" % lgs.score(X_test, y_test))  #checking the accuracy\n",
        "print(\"Precision: %f\" % metrics.precision_score(y_test, predicted))\n",
        "print(\"Recall: %f\" % metrics.recall_score(y_test, predicted))\n",
        "print(\"F1-Score: %f\" % metrics.f1_score(y_test, predicted))\n",
        "print(\"AUC: %f\" % auc)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------\n",
            "Accuracy: 0.865600\n",
            "Precision: 0.858641\n",
            "Recall: 0.877729\n",
            "F1-Score: 0.868080\n",
            "AUC: 0.934383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB-JtFyVf9Ea"
      },
      "source": [
        "TEST_CLEAN_DATA = 'test_clean.csv'\n",
        "\n",
        "test_data = pd.read_csv(DATA_IN_PATH + TEST_CLEAN_DATA)\n",
        "\n",
        "test_review = list(test_data['review'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVlctKDuf9Ea",
        "outputId": "ff4c07df-38df-4294-8a68-5c696aef84ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_data.head(5)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>naturally film main themes mortality nostalgia...</td>\n",
              "      <td>\"12311_10\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>movie disaster within disaster film full great...</td>\n",
              "      <td>\"8348_2\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>movie kids saw tonight child loved one point k...</td>\n",
              "      <td>\"5828_4\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>afraid dark left impression several different ...</td>\n",
              "      <td>\"7186_2\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>accurate depiction small time mob life filmed ...</td>\n",
              "      <td>\"12128_7\"</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review          id\n",
              "0  naturally film main themes mortality nostalgia...  \"12311_10\"\n",
              "1  movie disaster within disaster film full great...    \"8348_2\"\n",
              "2  movie kids saw tonight child loved one point k...    \"5828_4\"\n",
              "3  afraid dark left impression several different ...    \"7186_2\"\n",
              "4  accurate depiction small time mob life filmed ...   \"12128_7\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxi3nzLCf9Ea"
      },
      "source": [
        "test_sentences = list()\n",
        "for review in test_review:\n",
        "    test_sentences.append(review.split())"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htATuE5gf9Ea",
        "outputId": "505f1fea-c1cb-4a2a-9a69-a54d237ed490",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data_vecs = get_dataset(test_sentences, model, num_features)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z00KTFGf9Ea"
      },
      "source": [
        "test_predicted = lgs.predict(test_data_vecs)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O22emBjbf9Ea"
      },
      "source": [
        "ids = list(test_data['id'])\n",
        "\n",
        "answer_dataset = pd.DataFrame({'id': ids, 'sentiment': test_predicted})"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB1i12qIf9Ea"
      },
      "source": [
        "if not os.path.exists(DATA_OUT_PATH):\n",
        "    os.makedirs(DATA_OUT_PATH)\n",
        "\n",
        "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_w2v_answer.csv', index=False, quoting=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYkPv8AJNoFm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}